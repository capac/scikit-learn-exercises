{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Richter's Predictor: Modeling Earthquake Damage\n",
    "\n",
    "Hosted By _DrivenData_ at ['Richter's Predictor: Modeling Earthquake Damage'](https://www.drivendata.org/competitions/57/nepal-earthquake/).\n",
    "\n",
    "The dataset mainly consists of information on the buildings' structure and their legal ownership. Each row in the dataset represents a specific building in the region that was hit by the Gorkha earthquake.\n",
    "\n",
    "We're trying to predict the ordinal variable `damage_grade`, which represents a level of damage to the building that was hit by the earthquake. There are 3 grades of the damage:\n",
    "\n",
    " 1. represents low damage\n",
    " 2. represents a medium amount of damage\n",
    " 3. represents almost complete destruction\n",
    "\n",
    "The level of damage is an ordinal variable meaning that ordering is important. This can be viewed as a classification or an ordinal regression problem. \n",
    " \n",
    "To measure the performance of our algorithms, we'll use the _F1 score_ which balances the precision and recall of a classifier. Traditionally, the F1 score is used to evaluate performance on a binary classifier, but since we have three possible labels we will use a variant called the _micro averaged F1 score_.\n",
    " \n",
    " - [Loading data](#Loading-data)\n",
    " - [Exploratory data analysis](#Exploratory-data-analysis)\n",
    " - [Correlation](#Correlation)\n",
    " - [Model training](#Model-training)\n",
    " - [Grid search with cross validation](#Grid-search-with-cross-validation)\n",
    "    - [XGB Classifier](#XGB-Classifier)\n",
    " - [Ensemble modeling](#Ensemble-modeling)\n",
    " - [Performance metric for DrivenData competition](#Performance-metric-for-DrivenData-competition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path, PurePath\n",
    "from time import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root_dir = Path('/Users/angelo/Programming/Python/driven-data/predicting-earthquake-damage')\n",
    "train_values_file = project_root_dir / 'data/train_values.csv'\n",
    "train_labels_file = project_root_dir / 'data/train_labels.csv'\n",
    "test_values_file = project_root_dir / 'data/test_values.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values_df = pd.read_csv(train_values_file, index_col='building_id')\n",
    "test_values_df = pd.read_csv(test_values_file, index_col='building_id')\n",
    "train_labels_df = pd.read_csv(train_labels_file, index_col='building_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train_values_df.shape: {train_values_df.shape}\\ntrain_labels_df.shape: {train_labels_df.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train_values_df.index.nunique(): {train_values_df.index.nunique()}\\ntrain_labels_df.index.nunique(): {train_labels_df.index.nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'(train_values_df.index.sort_values() == train_labels_df.index.sort_values()).all(): \\\n",
    "{(train_values_df.index.sort_values() == train_labels_df.index.sort_values()).all()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataframes = [train_values_df, test_values_df]\n",
    "all_regexes = ['geo_level_']\n",
    "for df in all_dataframes:\n",
    "    for reg in all_regexes:\n",
    "        filter_ = train_values_df.filter(regex=reg).columns\n",
    "        df[filter_] = df[filter_].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_objects = ['land_surface_condition', 'foundation_type', 'roof_type', 'ground_floor_type', \\\n",
    "                 'other_floor_type', 'position',  'plan_configuration', 'legal_ownership_status']\n",
    "for df in all_dataframes:\n",
    "    df[other_objects] = df[other_objects].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for df in all_dataframes:\n",
    "#     df.drop(['geo_level_2_id', 'geo_level_3_id'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attrib = train_values_df.select_dtypes('int64').columns\n",
    "cat_attrib = train_values_df.select_dtypes('category').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id',\n",
       "       'land_surface_condition', 'foundation_type', 'roof_type',\n",
       "       'ground_floor_type', 'other_floor_type', 'position',\n",
       "       'plan_configuration', 'legal_ownership_status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_attrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['count_floors_pre_eq', 'age', 'area_percentage', 'height_percentage',\n",
       "       'has_superstructure_adobe_mud', 'has_superstructure_mud_mortar_stone',\n",
       "       'has_superstructure_stone_flag',\n",
       "       'has_superstructure_cement_mortar_stone',\n",
       "       'has_superstructure_mud_mortar_brick',\n",
       "       'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
       "       'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
       "       'has_superstructure_rc_engineered', 'has_superstructure_other',\n",
       "       'count_families', 'has_secondary_use', 'has_secondary_use_agriculture',\n",
       "       'has_secondary_use_hotel', 'has_secondary_use_rental',\n",
       "       'has_secondary_use_institution', 'has_secondary_use_school',\n",
       "       'has_secondary_use_industry', 'has_secondary_use_health_post',\n",
       "       'has_secondary_use_gov_office', 'has_secondary_use_use_police',\n",
       "       'has_secondary_use_other'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_attrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values_df[num_attrib] = train_values_df[num_attrib].astype('int32')\n",
    "test_values_df[num_attrib] = test_values_df[num_attrib].astype('int32')\n",
    "train_labels_df['damage_grade'] = train_labels_df['damage_grade'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 260601 entries, 802906 to 747594\n",
      "Data columns (total 38 columns):\n",
      " #   Column                                  Non-Null Count   Dtype   \n",
      "---  ------                                  --------------   -----   \n",
      " 0   geo_level_1_id                          260601 non-null  category\n",
      " 1   geo_level_2_id                          260601 non-null  category\n",
      " 2   geo_level_3_id                          260601 non-null  category\n",
      " 3   count_floors_pre_eq                     260601 non-null  int32   \n",
      " 4   age                                     260601 non-null  int32   \n",
      " 5   area_percentage                         260601 non-null  int32   \n",
      " 6   height_percentage                       260601 non-null  int32   \n",
      " 7   land_surface_condition                  260601 non-null  category\n",
      " 8   foundation_type                         260601 non-null  category\n",
      " 9   roof_type                               260601 non-null  category\n",
      " 10  ground_floor_type                       260601 non-null  category\n",
      " 11  other_floor_type                        260601 non-null  category\n",
      " 12  position                                260601 non-null  category\n",
      " 13  plan_configuration                      260601 non-null  category\n",
      " 14  has_superstructure_adobe_mud            260601 non-null  int32   \n",
      " 15  has_superstructure_mud_mortar_stone     260601 non-null  int32   \n",
      " 16  has_superstructure_stone_flag           260601 non-null  int32   \n",
      " 17  has_superstructure_cement_mortar_stone  260601 non-null  int32   \n",
      " 18  has_superstructure_mud_mortar_brick     260601 non-null  int32   \n",
      " 19  has_superstructure_cement_mortar_brick  260601 non-null  int32   \n",
      " 20  has_superstructure_timber               260601 non-null  int32   \n",
      " 21  has_superstructure_bamboo               260601 non-null  int32   \n",
      " 22  has_superstructure_rc_non_engineered    260601 non-null  int32   \n",
      " 23  has_superstructure_rc_engineered        260601 non-null  int32   \n",
      " 24  has_superstructure_other                260601 non-null  int32   \n",
      " 25  legal_ownership_status                  260601 non-null  category\n",
      " 26  count_families                          260601 non-null  int32   \n",
      " 27  has_secondary_use                       260601 non-null  int32   \n",
      " 28  has_secondary_use_agriculture           260601 non-null  int32   \n",
      " 29  has_secondary_use_hotel                 260601 non-null  int32   \n",
      " 30  has_secondary_use_rental                260601 non-null  int32   \n",
      " 31  has_secondary_use_institution           260601 non-null  int32   \n",
      " 32  has_secondary_use_school                260601 non-null  int32   \n",
      " 33  has_secondary_use_industry              260601 non-null  int32   \n",
      " 34  has_secondary_use_health_post           260601 non-null  int32   \n",
      " 35  has_secondary_use_gov_office            260601 non-null  int32   \n",
      " 36  has_secondary_use_use_police            260601 non-null  int32   \n",
      " 37  has_secondary_use_other                 260601 non-null  int32   \n",
      "dtypes: category(11), int32(27)\n",
      "memory usage: 32.5 MB\n"
     ]
    }
   ],
   "source": [
    "train_values_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geo_level_1_id: [6, 8, 21, 22, 11, ..., 24, 28, 23, 2, 29]\n",
      "Length: 31\n",
      "Categories (31, int64): [6, 8, 21, 22, ..., 28, 23, 2, 29]\n",
      "geo_level_2_id: [487, 900, 363, 418, 131, ..., 975, 771, 77, 115, 627]\n",
      "Length: 1414\n",
      "Categories (1414, int64): [487, 900, 363, 418, ..., 771, 77, 115, 627]\n",
      "geo_level_3_id: [12198, 2812, 8973, 10694, 1488, ..., 7039, 8947, 3152, 5276, 3085]\n",
      "Length: 11595\n",
      "Categories (11595, int64): [12198, 2812, 8973, 10694, ..., 8947, 3152, 5276, 3085]\n",
      "count_floors_pre_eq: [2 3 1 4 5 6 7 8 9]\n",
      "age: [ 30  10  25   0  15  20  45  55   5  40  80  60  35  70  50  65 100  75\n",
      "  85 190 995 105  90 120  95 110 115 150 200 130 125 140 155 160 175 135\n",
      " 145 195 180 165 170 185]\n",
      "area_percentage: [  6   8   5   9   3  13   7   4  12  16  11  27  10  15  14  17  21  37\n",
      "  19   2  28  38  56   1  20  24  34  26  18  31  25  23  22  32  47  36\n",
      "  40  29  42  55  35  39 100  50  51  43  30  62  85  33  45  52  57  49\n",
      "  67  66  54  75  65  58  48  64  63  46  59  86  78  41  44  61  70  77\n",
      "  73  72  53  60  84  83  76  96  80  90  82  69]\n",
      "height_percentage: [ 5  7  9  4  6  3 10  8  2 32 12 11 13 16 15 18 26 17 19 14 20 23 21 25\n",
      " 24 28 31]\n",
      "land_surface_condition: ['t', 'o', 'n']\n",
      "Categories (3, object): ['t', 'o', 'n']\n",
      "foundation_type: ['r', 'w', 'i', 'u', 'h']\n",
      "Categories (5, object): ['r', 'w', 'i', 'u', 'h']\n",
      "roof_type: ['n', 'q', 'x']\n",
      "Categories (3, object): ['n', 'q', 'x']\n",
      "ground_floor_type: ['f', 'x', 'v', 'z', 'm']\n",
      "Categories (5, object): ['f', 'x', 'v', 'z', 'm']\n",
      "other_floor_type: ['q', 'x', 'j', 's']\n",
      "Categories (4, object): ['q', 'x', 'j', 's']\n",
      "position: ['t', 's', 'j', 'o']\n",
      "Categories (4, object): ['t', 's', 'j', 'o']\n",
      "plan_configuration: ['d', 'u', 's', 'q', 'm', 'c', 'a', 'n', 'f', 'o']\n",
      "Categories (10, object): ['d', 'u', 's', 'q', ..., 'a', 'n', 'f', 'o']\n",
      "has_superstructure_adobe_mud: [1 0]\n",
      "has_superstructure_mud_mortar_stone: [1 0]\n",
      "has_superstructure_stone_flag: [0 1]\n",
      "has_superstructure_cement_mortar_stone: [0 1]\n",
      "has_superstructure_mud_mortar_brick: [0 1]\n",
      "has_superstructure_cement_mortar_brick: [0 1]\n",
      "has_superstructure_timber: [0 1]\n",
      "has_superstructure_bamboo: [0 1]\n",
      "has_superstructure_rc_non_engineered: [0 1]\n",
      "has_superstructure_rc_engineered: [0 1]\n",
      "has_superstructure_other: [0 1]\n",
      "legal_ownership_status: ['v', 'a', 'r', 'w']\n",
      "Categories (4, object): ['v', 'a', 'r', 'w']\n",
      "count_families: [1 0 2 3 4 5 6 7 9 8]\n",
      "has_secondary_use: [0 1]\n",
      "has_secondary_use_agriculture: [0 1]\n",
      "has_secondary_use_hotel: [0 1]\n",
      "has_secondary_use_rental: [0 1]\n",
      "has_secondary_use_institution: [0 1]\n",
      "has_secondary_use_school: [0 1]\n",
      "has_secondary_use_industry: [0 1]\n",
      "has_secondary_use_health_post: [0 1]\n",
      "has_secondary_use_gov_office: [0 1]\n",
      "has_secondary_use_use_police: [0 1]\n",
      "has_secondary_use_other: [0 1]\n"
     ]
    }
   ],
   "source": [
    "for col in list(train_values_df.columns):\n",
    "    print(f'{col}: {train_values_df[col].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "land_surface_condition: [<class 'str'>, <class 'str'>, <class 'str'>]\n"
     ]
    }
   ],
   "source": [
    "print(f'''land_surface_condition: {[type(item) for item in train_values_df['land_surface_condition'].unique()]}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_labels_df['damage_grade'].values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values_df.nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values_df.describe().applymap('{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values_df.nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_num_attrib_list = list(num_attrib)\n",
    "mod_num_attrib_list.append(train_labels_df.columns[-1])\n",
    "mod_num_attrib_df = train_values_df.join(train_labels_df)[mod_num_attrib_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_num_attrib_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir = project_root_dir / 'exploratory_data_analysis/plots'\n",
    "model_dir = project_root_dir / 'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import ticker\n",
    "scale = 1e4\n",
    "ticks = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set(style='ticks', color_codes=True)\n",
    "fig, axes = plt.subplots(figsize=(10, 6))\n",
    "df = train_labels_df['damage_grade'].value_counts(ascending=False).sort_index()\n",
    "axes.bar(df.index, df.values, color=plt.cm.tab10.colors, edgecolor='k')\n",
    "axes.set_xlabel('Level', fontsize=14)\n",
    "axes.set_ylabel('Number of damaged buildings (in units of $10^4$)', fontsize=14)\n",
    "axes.set_title('Building damage by level', fontsize=16)\n",
    "axes.set_xticks(df.index)\n",
    "axes.set_xticklabels(['Low', 'Medium', 'High'], fontsize=14)\n",
    "plt.setp(axes.get_yticklabels(), fontsize=14)\n",
    "axes.yaxis.set_major_formatter(ticks)\n",
    "plt.savefig(PurePath.joinpath(plot_dir, 'damage-level-by-grade.png'), dpi=288);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "label_font_size = 14\n",
    "pairplot_file = PurePath.joinpath(plot_dir, 'pairplot.png')\n",
    "if pairplot_file.is_file():\n",
    "    from IPython.display import Image\n",
    "    display(Image(filename = pairplot_file))\n",
    "else:\n",
    "    g = sns.PairGrid(mod_num_attrib_df, hue='damage_grade', palette='tab10', height=3.0, aspect=1.2)\n",
    "    g = g.map_diag(plt.hist)\n",
    "    g = g.map_offdiag(plt.scatter, s=60, alpha=0.6)\n",
    "    g = g.add_legend()\n",
    "#     print(g._legend.__dir__())\n",
    "#     g._legend._set_loc('center left')\n",
    "#     g._legend.set_bbox_to_anchor((1, 0.5, 1, 2))\n",
    "    g._legend.set_title('Damage Level', prop={'size': label_font_size})\n",
    "    for txt, lb in zip(g._legend.texts, ['Low', 'Medium', 'High']):\n",
    "        txt.set_text(lb)\n",
    "        txt.set_fontsize(label_font_size)\n",
    "\n",
    "    xlabels, ylabels = [], []\n",
    "\n",
    "    for ax in g.axes[-1,:]:\n",
    "        xlabel = ax.xaxis.get_label_text()\n",
    "        xlabels.append(xlabel)\n",
    "    for ax in g.axes[:,0]:\n",
    "        ylabel = ax.yaxis.get_label_text()\n",
    "        ylabels.append(ylabel)\n",
    "        \n",
    "    for i in range(len(xlabels)):\n",
    "        for j in range(len(ylabels)):\n",
    "            g.axes[j, i].xaxis.set_label_text(xlabels[i])\n",
    "            g.axes[j, i].xaxis.label.set_size(label_font_size)\n",
    "            g.axes[j, i].tick_params(axis='x', which='major', labelsize=label_font_size)\n",
    "            g.axes[j, i].yaxis.set_label_text(ylabels[j])\n",
    "            g.axes[j, i].yaxis.label.set_size(label_font_size)\n",
    "            g.axes[j, i].tick_params(axis='y', which='major', labelsize=label_font_size)\n",
    "\n",
    "    plt.tight_layout(rect=(0, 0, 0.92, 1))\n",
    "    plt.savefig(pairplot_file, dpi=288)\n",
    "print(f'Time elasped: {time() - t0:.4f} sec');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Categorical columns: {list(cat_attrib)}\\n')\n",
    "print(f'Number of categorical columns: {len(cat_attrib)}\\n')\n",
    "\n",
    "binary_cat_attrib = list(train_values_df.filter(regex='has_').columns)\n",
    "geo_id_cat_attrib = list(train_values_df.filter(regex='geo_level_').columns)\n",
    "print(f'Number of binary categorical columns: {len(binary_cat_attrib)}\\n')\n",
    "\n",
    "list_tuple_binary_cat_attrib = [(binary_cat_attrib[i], binary_cat_attrib[j]) for i, j in \\\n",
    "                                zip(range(0, len(binary_cat_attrib)-1, 2), range(1, len(binary_cat_attrib), 2))]\n",
    "\n",
    "print(f'List of tuples: {list_tuple_binary_cat_attrib}\\n')\n",
    "print(f'Number of tuples: {len(list_tuple_binary_cat_attrib)}\\n')\n",
    "\n",
    "list_remainders = list(set(cat_attrib) - set(binary_cat_attrib) - set(geo_id_cat_attrib))\n",
    "print(f'Remainder columns: {list(list_remainders)}\\n')\n",
    "print(f'Number of reminder columns: {len(list_remainders)}\\n')\n",
    "\n",
    "list_tuple_remainders = [(list_remainders[i], list_remainders[j]) for i, j in \\\n",
    "                         zip(range(0, len(list_remainders)-1, 2), range(1, len(list_remainders), 2))]\n",
    "print(f'List tuple remainders: {list_tuple_remainders}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot(ax, df, col):\n",
    "    for i in range(0, 2):\n",
    "        df_col = df[col[i]].value_counts(ascending=False)\n",
    "        df_col = df_col/df_col.sum()*100\n",
    "        df_col = df_col.reset_index().rename(columns={'index': 'features'})\n",
    "        ax[i].bar(df_col['features'], df_col[col[i]], color=colors, edgecolor='k')        \n",
    "        if all(isinstance(tick, np.float64) for tick in ax[i].get_xticks()):\n",
    "            ax[i].set_xticks(range(0, 2))\n",
    "            ax[i].set_xticklabels(['No', 'Yes'])\n",
    "        plt.setp(ax[i].get_xticklabels(), ha=\"right\", rotation_mode=\"anchor\", rotation=0, fontsize=14)\n",
    "        plt.setp(ax[i].get_yticklabels(), fontsize=14)\n",
    "        ax[i].set_ylabel('Percent (%)', fontsize=14)\n",
    "        ax[i].set_title(col[i], fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(14, 12))\n",
    "colors = plt.cm.tab10.colors\n",
    "for ax, col in zip(axes, list_tuple_remainders):\n",
    "    bar_plot(ax, train_values_df, col)\n",
    "plt.tight_layout()\n",
    "plt.savefig(PurePath.joinpath(plot_dir, 'categorical-bar-plot-1.png'), dpi=288);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=11, ncols=2, figsize=(14, 30))\n",
    "for ax, col in zip(axes, list_tuple_binary_cat_attrib):\n",
    "    bar_plot(ax, train_values_df, col)\n",
    "plt.tight_layout()\n",
    "plt.savefig(PurePath.joinpath(plot_dir, 'categorical-bar-plot-2.png'), dpi=288);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(10, 6))\n",
    "mask = np.zeros_like(train_values_df[num_attrib].corr())\n",
    "mask[np.tril_indices_from(mask)] = True\n",
    "hm = sns.heatmap(data=train_values_df[num_attrib].corr(), cmap='Spectral', ax=axes, annot=True, fmt='1.4f', mask=mask, annot_kws={'size': 14})\n",
    "axes.tick_params(labelsize=14)\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "plt.setp(axes.get_xticklabels(), ha='right', rotation_mode='anchor', rotation=45)\n",
    "plt.setp(axes.get_yticklabels(), ha='right', rotation_mode='anchor')\n",
    "plt.tight_layout()\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.savefig(PurePath.joinpath(plot_dir, 'correlation.png'), dpi=288);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from joblib import dump, load\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_df_copy = train_labels_df.copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_labels_df[['damage_grade']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([('imputer', SimpleImputer(strategy='median')), ('std_scaler', StandardScaler())])\n",
    "full_pipeline = ColumnTransformer([('num', num_pipeline, num_attrib), ('cat', OneHotEncoder(), cat_attrib)])\n",
    "train_values_prepared_df = full_pipeline.fit_transform(train_values_df)\n",
    "# label_pipeline = OrdinalEncoder()\n",
    "# train_labels_prepared_df = label_pipeline.fit_transform(train_labels_df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_values_prepared_df, train_labels_df, test_size = 0.3, random_state=42)\n",
    "y_train, y_test = y_train.iloc[:,0], y_test.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (182420, 13105)\n",
      "X_test.shape: (78181, 13105)\n",
      "y_train.shape: (182420,)\n",
      "y_test.shape: (78181,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train.shape: {X_train.shape:}\\nX_test.shape: {X_test.shape}\\n\\\n",
    "y_train.shape: {y_train.shape}\\ny_test.shape: {y_test.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ntuple = namedtuple('clf_ntuple', ['name', 'classifier'])\n",
    "# lin_svc_clf = clf_ntuple(name='lin_svc_clf', classifier=LinearSVC(dual=False, random_state=42))\n",
    "lr_clf = clf_ntuple(name='lr_clf', classifier=LogisticRegression(random_state=42, n_jobs=-1))\n",
    "# dt_clf = clf_ntuple(name='dt_clf', classifier=DecisionTreeClassifier(random_state=42))\n",
    "# rf_clf = clf_ntuple(name='rf_clf', classifier=RandomForestClassifier(random_state=42, n_jobs=-1))\n",
    "xgb_clf = clf_ntuple(name='xgb_clf', classifier=XGBClassifier(n_jobs=-1))\n",
    "# clf_tuple = (lin_svc_clf, lr_clf, dt_clf, rf_clf, xgb_clf)\n",
    "clf_tuple = (lr_clf, xgb_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(model_clf, t, X_test, y_test):\n",
    "    y_pred = model_clf.predict(X_test)\n",
    "    acc_score = accuracy_score(y_pred, y_test)\n",
    "    print(f'Accuracy score for {model_clf.__class__.__name__}: {acc_score:.6f}', end=', ')\n",
    "    print(f'time elapsed: {time() - t:.4f} sec')\n",
    "    print(f'\\nClassification report: {classification_report(y_pred, y_test)}')\n",
    "    return acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/angelo/Programming/Python/driven-data/predicting-earthquake-damage/models\n"
     ]
    }
   ],
   "source": [
    "print(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for LogisticRegression: 0.734143, time elapsed: 0.0248 sec\n",
      "\n",
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.67      0.54      5244\n",
      "           2       0.84      0.73      0.78     50866\n",
      "           3       0.63      0.75      0.68     22071\n",
      "\n",
      "    accuracy                           0.73     78181\n",
      "   macro avg       0.64      0.72      0.67     78181\n",
      "weighted avg       0.76      0.73      0.74     78181\n",
      "\n",
      "Accuracy score for XGBClassifier: 0.725995, time elapsed: 1.9924 sec\n",
      "\n",
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.71      0.55      4816\n",
      "           2       0.87      0.71      0.78     53849\n",
      "           3       0.57      0.76      0.65     19516\n",
      "\n",
      "    accuracy                           0.73     78181\n",
      "   macro avg       0.63      0.73      0.66     78181\n",
      "weighted avg       0.77      0.73      0.74     78181\n",
      "\n",
      "\n",
      "Total time elasped: 2.1822 sec\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "list_files = [x for x in model_dir.iterdir() if x.is_file]\n",
    "accuracy_score_dict = dict()\n",
    "for tup in clf_tuple:\n",
    "    model_file = PurePath.joinpath(model_dir, tup.name+'.sav')\n",
    "    if model_file in list_files:\n",
    "        t1 = time()\n",
    "        model_clf = load(model_file)\n",
    "        accuracy_score_dict[model_clf.__class__.__name__] = print_accuracy(model_clf, t1, X_test, y_test)\n",
    "    else:\n",
    "        t2 = time()\n",
    "        tup.classifier.fit(X_train, y_train)\n",
    "        dump(tup.classifier, model_file)\n",
    "        accuracy_score_dict[tup.classifier.__class__.__name__] = print_accuracy(tup.classifier, t2, X_test, y_test)\n",
    "print(f'\\nTotal time elasped: {time() - t0:.4f} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search with cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "train_values_dask_df = dd.from_pandas(train_values_df, npartitions=6)\n",
    "train_labels_dask_df = dd.from_pandas(train_labels_df, npartitions=6)\n",
    "test_values_dask_df = dd.from_pandas(test_values_df, npartitions=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_values_dask_df = train_values_dask_df.drop(['geo_level_2_id', 'geo_level_3_id'], axis=1)\n",
    "# test_values_dask_df = test_values_dask_df.drop(['geo_level_2_id', 'geo_level_3_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.xgboost import XGBClassifier\n",
    "from dask.distributed import Client\n",
    "client = Client(n_workers=2, threads_per_worker=2, memory_limit='12GB')\n",
    "xgb_clf = XGBClassifier()\n",
    "xgb_clf.fit(train_values_dask_df, train_labels_dask_df)\n",
    "# xgb_params = {'max_depth': [50, 100], 'n_estimators':[100, 200], 'n_jobs': [-1]}\n",
    "# xgb_grid_search = GridSearchCV(xgb_clf, xgb_params, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "# xgb_joblib_file = PurePath.joinpath(model_dir, 'xgb_grid_search.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_func(grid_search, joblib_file):\n",
    "    t0 = time()\n",
    "    if joblib_file.is_file():\n",
    "        grid_search = load(joblib_file)\n",
    "    else:\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        dump(grid_search, joblib_file)\n",
    "    print(f'Best parameters for grid search: {grid_search.best_params_}\\n')\n",
    "    print(f'Best estimator for grid search: {grid_search.best_estimator_}\\n')\n",
    "    print(f'Time elapsed: {time() - t0:.4f} sec')\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid_search_output = grid_search_func(xgb_grid_search, xgb_joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_results(grid_search, num):\n",
    "    cvres = grid_search.cv_results_\n",
    "    best_fit_models = [(np.sqrt(-mean_score), params) for mean_score, params in zip(cvres['mean_test_score'], cvres['params'])]\n",
    "    best_fit_models.sort(key=lambda x: x[0], reverse=False)\n",
    "    print(f'List of best-fit models sorted by RMSE:')\n",
    "    for rmse, params in best_fit_models[:num]:\n",
    "        print(f'{rmse} {params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results(lin_svc_grid_search_output, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lin_svc_grid_search_output.predict(X_test)\n",
    "best_fit_acc_score = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy for the best-fit model: {best_fit_acc_score:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''We have a {(100*(best_fit_acc_score-accuracy_score_dict['XGBClassifier'])/accuracy_score_dict['XGBClassifier']):.4f}% improvement.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_est_clf = clf_ntuple(name='grid_search.best_estimator_', classifier=xgb_grid_search_output.best_estimator_)\n",
    "lin_svc_clf = clf_ntuple(name='lin_svc_clf', classifier=LinearSVC(C=1e3, dual=False, random_state=42))\n",
    "new_clf_tuple = (lin_svc_clf, lr_clf, dt_clf, rf_clf, best_est_clf)\n",
    "tupl_list = [(tupl.name, tupl.classifier) for tupl in new_clf_tuple]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(estimators=tupl_list, voting='hard', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "joblib_file = PurePath.joinpath(model_dir, 'voting_clf.sav')\n",
    "if joblib_file.is_file():\n",
    "    voting_clf = load(joblib_file)\n",
    "else:\n",
    "    voting_clf.fit(X_train, y_train)\n",
    "    dump(voting_clf, joblib_file)\n",
    "print(f'Time elapsed: {time() - t0:.4f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "y_prediction_voting_clf = voting_clf.predict(X_test)\n",
    "accuracy_score_voting_clf = accuracy_score(y_prediction_voting_clf, y_test)\n",
    "print(f'Time elapsed: {time() - t0:.4f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score_dict.update({'GridSearchCV': best_fit_acc_score, 'VotingClassifier': accuracy_score_voting_clf})\n",
    "sorted_acc_score = [(val, key) for key, val in accuracy_score_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_acc_score.sort(key=lambda val: val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for score, name in sorted_acc_score:\n",
    "    print(f'''Accuracy score for {name + ':':<25} {score:.6f}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance metric for DrivenData competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''Micro-averaged F1 score for the VotingClassifier classifier: {f1_score(y_test, y_pred, average='micro'):.8f}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
